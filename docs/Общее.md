# Основы  
  
## Цель  
  
Цель сервиса - брать на себя работу по любой трансформации исходных данных клиентов, — облаков точек и сопутствующей к ним информации, — в продукты. Достижение этой цели упрощается при использовании инструментов и практик, рекомендации по которым в тексте ниже. 

___
## Некоторые сущности
### Пайплайн

Превращение вещи A в вещь Б (даже если Б - это новая форма А) происходит в пайплайнах. Под "пайплайном" мы понимаем любую последовательность действий над исходником, будь то извлечение информации и/или преобразование в нечто новое. Важный нюанс - любая манипуляция только в рамках своего собственного этапа. Решение задачи в одной зоне ответственности - это единичный этап.

### Скан (scan)

Скан - это любой результат лазерного сканирования. Единичный проход. Входящее в состав облако точек само по себе не представляет интереса. Польза рождается только с помощью сопутствующей к нему информации - контрольных (опорных) точек, выбранной системе координат реального мира, траектории движения и т.п.

Если в состав комплекса мобильного лазерного сканирования (далее - MLS) входит не только LIDAR + IMU + GNSS приёмник, но и камера, то вам, благодаря наличию видеосъёмки, открываются дополнительные возможности для продвинутых задач.

Немаловажную роль камера играет для пайплайнов, где вы напрямую или вовсе не используете облако точек, например, - детекция и классификация знаков дорожного движения. Помните и про возможности ручной валидации результатов кластеризации, сегментации и/или классификации облаков точек путём просмотра видео с этих же участков.

### Съёмка (dataset)

Когда сцена перестаёт ограничиваться маленьким участком улицы, который уместился бы в упомянутый выше скан, мы начинаем манипулировать со съёмками. Съёмка - это набор сканов, сделанных с целью запечатления одной сцены. Один скан - кухня, второй - гостиная, но в совокупности - съёмка квартиры.

В написании пайплайнов мы говорим dataset, а не съёмка, потому что смотрим на неё через призму набора данных (data set). Воспринимаем соответствующе.

Важное замечание. Съёмка, по-хорошему, не отличается конфигурацией MLS - каждый скан сделан с одинаковыми настройками. Что достаточно критично,  - с одинаковым датумом (WGS-84, CGCS2000). Нарушение этих правил ещё не конец света, но вам придётся запариться с парсингом метаданных и поиском полей с соответствующей информацией (которой может и не быть), а потом решать задачу - как мне всё это трансформировать с минимальной погрешностью.

### Клиент (company и department)

Это потребитель результатов обработчика. Сейчас главный портал, откуда мы должны брать задачи обработчику, - сайт. На сайте компания имеет свою учётную запись и может приглашать к себе своих работников, а те затем распределяются по тематическим отделам, они же department.

Разные юзеры имеют свои права или доступные услуги, за которыми скрываются сконфигурированные и набитые наборами (съёмками) со сканами пайплайны нашего обработчика. Вы же ещё не забыли, что мы называем пайплайном, сканом и съёмками, да?

Как мы именно связываемся с клиентом - отдельный разговор.

___
## Temporal. Главный инструмент пайплайнов
### Обоснование применения

Он банально даёт всё, что нужно, и даже с горочкой, для оркестрации пайплайнов. Можно сказать, что мы строим их целиком и полностью благодаря Temporal SDK на Python, а именно Temporal Workflow.

Интересующие нас преимущества:
- долгоживущие и легко воскрешаемые workflow;
- детерминизм и воспроизводимость процессов;
- легко следить за пайплайном;
- несложно делать "human-in-loop" для QC и поправок клиентов;
- retry инструменты из коробки;
- горизонтально расширяемо добавлением новых worker.

С какими минусами мы смиряемся:
- детерминизм процессов;
- за пайплайном нужно следить;
- нужно следить за пайплайном и писать для этого кучу health-check'ов.

___
### Устоявшиеся правила и советы

#### Пайплайны и workflow

> [!tip]  Совет
> 
Любой путь облаков из вида А в вид/продукт Б должен быть реализован через workflow от Temporal.  

Каждый из шагов на таком пути должен быть выделен в свою activity от Temporal. Одна activity - одна зона ответственности.  

#### Heartbeat и Query

- Не забывайте писать ~~(иначе я сверну вам шею)~~:  
	- Temporal Heartbeat для ваших долгих activity;  
	- Temporal Query для проверки прогресса внутри workflow.

#### Стук в дверь workflow

> [!tip]  Совет
> Если хотите дать команду воркфлоу, юзайте Temporal Signal/Update. Первое асинхронно, но ничё не обещает, второе синхронно, но гарантирует обратную связь.

#### Дубликаты activities в разных workflow

> [!tip]  Совет
> Если шаг из workflow в workflow начинает повторяться, его необходимо выносить на уровень выше, чем просто activity конкретного workflow. Например, в тематическую репу (как repo.py).  

#### Большие workflow

> [!tip]  Совет
> В основе создания любых больших ~~пайплайнов~~ workflow лежит дробление его ~~стадий~~ шагов на дочек. Для Temporal Workflow это child workflow. Пишите этапы как обычные воркфлоу, а потом делайте в каком-то оркеструющем/главном воркфлоу execute_child_workflow(...).  

#### Retry пайплайнов

> [!tip]  Совет
> Не стесняйтесь пользоваться RetryPolicy от Temporal.  

>[!warning] Внимание!
>Не забывайте пользоваться RetryPolicy от Temporal. 

#### Импорты activity's в ваши воркеры

> [!tip]  Совет
> Относитесь ответственно к написанию worker для ваших воркфлоу - никаких лишних импортов activity's. 

#### Как тестировать workflow

Если у вас есть готовый Temporal workflow, апробировать его работу можно:  
- халтурно, то есть очередным if-ом в cli.py;  
- по-человечески, написав новый script в директории /scripts;  
- попросив Максима, а он выберет что-то одно из двух выше.  

А вообще на этот счёт есть специальный материал у них в документации, [вот здесь](https://docs.temporal.io/develop/python/testing-suite).

___
## БД и S3
### Что и зачем

Любые программные операции с файлами в пайплайнах не должны происходить "по приколу". Для повышения прозрачности и тестируемости у нас есть State of Truth БД - в docker-compose.yaml это postgres_app. 

Ещё раз - бездумная программная работа с S3 запрещена. Изменили состояние? Пишите об этом в тематическую таблицу в БД. А ещё лучше использовать/писать готовые методы, которые берут на себя два этих момента сразу.  

___
### Устоявшиеся правила и советы
#### Временные файлы

Файлы, которые нужны временно, должны быть временными и сразу утилизироваться после валидации успешного выполнения куска кода (потребителя) или человеком, или ответственной сущностью.  
Все временные артефакты складывайте в `point_cloud/tmp`, например hexbin GeoJSON — в `point_cloud/tmp/hexbin/<scan_id>/<scan_id>.geojson`.

#### Файлы для работы

Файлы любого размера для любой задачи, которая когда-то потом гарантированно будет (в ~~пайплайнах~~ workflow, проверках супервизоров, работе аналитиков и тестеров), должны складываться в S3 хранилище. У нас это MinIO. 
___
## Безопасность

Любые секреты в дефолтах, docker-compose и т.п. запрещены. Используйте .env файлы и их производные. Если прям впадлу, юзайте .env.example от Максима.

Дружеское напоминание не кидать в репозиторий что-то, что содержит секреты.  

Уделяйте внимание организации директорий под ваши новые фичи. Безответственное отношение грозит ~~мозготрахом~~ проблемами с импортами в других файлах.
